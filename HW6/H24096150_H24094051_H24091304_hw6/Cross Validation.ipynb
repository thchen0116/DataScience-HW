{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "X=train[\"tweet\"]\n",
    "Y=train[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score\n",
    "def score(pred_Y,test_Y):\n",
    "    \n",
    "    #AllF\n",
    "    list_score_all=f1_score(pred_Y,test_Y,average=None)\n",
    "    score_all=np.mean(list_score_all)\n",
    "    \n",
    "    #HateF\n",
    "    h_pred_Y=pred_Y.copy()\n",
    "    h_test_Y=test_Y.copy()\n",
    "    h_pred_Y[h_pred_Y==2]=1\n",
    "    h_test_Y[h_test_Y==2]=1\n",
    "    list_score_hate=f1_score(h_pred_Y,h_test_Y,average=None)\n",
    "    score_hate=np.mean(list_score_hate)\n",
    "    \n",
    "#     print(\"HateF:\",score_hate)\n",
    "#     print(\"AllF:\",score_all)\n",
    "#     print(\"Final:\",0.6*score_hate+0.4*score_all)\n",
    "    score_final=0.6*score_hate+0.4*score_all\n",
    "    return score_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "k=5\n",
    "n_samples=len(X)\n",
    "fold_size=n_samples//k\n",
    "scores=[]\n",
    "masks=[]\n",
    "for fold in range(k):\n",
    "    \n",
    "    #generate a boolean mask for the test set in this fold\n",
    "    test_mask=np.zeros(n_samples,dtype=bool)\n",
    "    test_mask[fold*fold_size:(fold+1)*fold_size]=True\n",
    "    \n",
    "    #create training and testing sets using this mask\n",
    "    test_X,test_Y=X[test_mask],Y[test_mask]\n",
    "    train_X,train_Y=X[~test_mask],Y[~test_mask]\n",
    "    \n",
    "    #TfidfVectorizer\n",
    "    tfidf=TfidfVectorizer()\n",
    "    tfidf.fit(train_X)\n",
    "    train_X=tfidf.transform(train_X)\n",
    "    test_X=tfidf.transform(test_X)\n",
    "    \n",
    "    #training\n",
    "    clf=XGBClassifier(eval_metric='mlogloss',use_label_encoder=False)\n",
    "    clf.fit(train_X,train_Y)\n",
    "    pred_Y=clf.predict(test_X)\n",
    "    scores.append(score(pred_Y,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6796019929301387, 0.6761227431118297, 0.6361164994319732, 0.6638705473304485, 0.6461884264531902]\n",
      "mean: 0.6603800418515161\n",
      "var: 0.0002839242226195708\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "print(scores)\n",
    "print(\"mean:\",np.mean(scores))\n",
    "print(\"var:\",np.var(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
